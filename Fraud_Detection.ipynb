{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import SparkSession\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import LogisticRegression"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/frauddetectionsmall.csv')\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#select data column\ndf2 = df.select(\"type\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", (col(\"isFraud\").cast(\"Int\").alias(\"label\")))\ndisplay(df2)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Split the data\nsplits = df2.randomSplit([0.7, 0.3])\ntrain = splits[0]"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows\ntrain.show(5)\ntest.show(5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["test.printSchema()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#defining Pipeline whihc provides a simple construction, tuning and testing for ML workflows.\nstrIdx = StringIndexer(inputCol = \"type\", outputCol = \"typeCat\")\nlabelIdx = StringIndexer(inputCol = \"label\", outputCol = \"idxLabel\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# number is meaningful so that it should be number features\ncatVect = VectorAssembler(inputCols = [\"typeCat\"], outputCol=\"catFeatures\")\ncatIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\nnumVect = VectorAssembler(inputCols = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"], outputCol=\"numFeatures\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# number vector is normalized\nminMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\nfeatVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["cl = []\npipeline = []\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["cl.insert(0, DecisionTreeClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\ncl.insert(1, RandomForestClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\ncl.insert(2, LogisticRegression(labelCol=\"idxLabel\", featuresCol=\"features\"))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Pipeline process the series of transformation above, which is 7 transformation\nfor i in range(3):\n    pipeline.insert(i, Pipeline(stages=[strIdx, labelIdx, catVect, catIdx, numVect, minMax, featVect, cl[i]]))\n    #piplineModel = pipeline.fit(train)\nprint \"Pipeline complete!\""],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Train Validation Split\n#we will used a train validation split instead of cross validation for every model because it takes much less time to train the model with the train validation split.\nmodel = []\n\n#When we will be using the whole dataset, we will use the TrainValidationSplit instead of the CrossValidator!\nparamGrid = (ParamGridBuilder().addGrid(cl[0].impurity, (\"gini\", \"entropy\")).addGrid(cl[0].maxDepth, [5, 10, 20]).addGrid(cl[0].maxBins, [5, 10, 20]).build())\ncv = CrossValidator(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, numFolds=5)\n#cv = TrainValidationSplit(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\nmodel.insert(0, cv.fit(train))\nprint \"Model 1 completed\"\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["paramGrid2 = (ParamGridBuilder().addGrid(cl[1].impurity, (\"gini\", \"entropy\")).addGrid(cl[1].maxDepth, [5, 10, 20]).addGrid(cl[1].maxBins, [5, 10, 20]).build())\ncv2 = CrossValidator(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, numFolds=5)\n#cv2 = TrainValidationSplit(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\nmodel.insert(1, cv2.fit(train))\nprint \"Model 2 completed\"\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["paramGrid3 = (ParamGridBuilder().addGrid(cl[2].regParam, [0.01, 0.5, 2.0]).addGrid(cl[2].threshold, [0.30, 0.35, 0.5]).addGrid(cl[2].maxIter, [1, 5]).addGrid(cl[2].elasticNetParam, [0.0, 0.5, 1]).build())\ncv3 = CrossValidator(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid3, numFolds=5)\n#cv3 = TrainValidationSplit(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\nmodel.insert(2, cv3.fit(train))\nprint \"Model 3 completed\""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#Test the model\nprediction = [] \npredicted = []\nfor i in range(3):\n  prediction.insert(i, model[i].transform(test))\n  predicted.insert(i, prediction[i].select(\"features\", \"prediction\", \"probability\", \"trueLabel\"))\n  predicted[i].show(30)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"Fraud_Detection","notebookId":688002291907907},"nbformat":4,"nbformat_minor":0}
